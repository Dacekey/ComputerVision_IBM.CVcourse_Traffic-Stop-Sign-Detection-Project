{"cells":[{"cell_type":"markdown","id":"99b21319-0526-4676-925d-8ddf43cf8c83","metadata":{},"outputs":[],"source":["<p style=\"text-align:center\">\n","    <a href=\"https://skills.network\" target=\"_blank\">\n","    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\">\n","    </a>\n","</p>\n"]},{"cell_type":"markdown","id":"4d09a916-3f29-4e6e-ab81-a242c1d66549","metadata":{},"outputs":[],"source":["<h1>Lab: Simple Neural Network for XOR</h1>\n"]},{"cell_type":"markdown","id":"212f8a20-b781-401c-b1b8-5df298b59ad7","metadata":{},"outputs":[],"source":["<h2>Objective</h2><p>After completing this lab you will be able to:</p> \n","<ul><li> Create a neural network model with multiple neurons to model a simple function.</li></ul>\n"]},{"cell_type":"markdown","id":"bb6467ff-b892-4800-a788-fa1cf623181e","metadata":{},"outputs":[],"source":["<h2>Table of Contents</h2>\n","<p>In this lab, you will see how many neurons it takes to classify noisy XOR data with one hidden layer neural network.</p>\n","\n","\n","- [Neural Network Module and Training Function](#Neural-Network-Module-and-Training-Function)\n","- [Make Some Data](#Make-Some-Data)\n","- [One Neuron](#One-Neuron)\n","- [Two Neurons](#Two-Neurons)\n","- [Three Neurons](#Three-Neurons)\n","\n","<p>Estimated Time Needed: <strong>25 min</strong></p>\n","<hr>\n"]},{"cell_type":"markdown","id":"9a0a344e-b306-480b-b20e-8111bba0390a","metadata":{},"outputs":[],"source":["<h2>Preparation</h2>\n"]},{"cell_type":"markdown","id":"7accd42d-7468-46b5-bbc8-c68329de2783","metadata":{},"outputs":[],"source":["We'll need the following libraries\n"]},{"cell_type":"code","id":"ef7502f9-e213-460b-8ee6-69198d4dfc77","metadata":{},"outputs":[],"source":["!pip3 install torch torchvision torchaudio\n!pip install matplotlib"]},{"cell_type":"code","id":"de41b07f-aee8-4874-961c-d9c617bc30b3","metadata":{},"outputs":[],"source":["# Import the libraries we need for this lab\n\n# Allows us to use arrays to manipulate and store data\nimport numpy as np\n# PyTorch Library\nimport torch\n# PyTorch Neural Network\nimport torch.nn as nn\n# Allows us to use activation functions\nimport torch.nn.functional as F\n# Used to graph data and loss curves\nimport matplotlib.pyplot as plt \nfrom matplotlib.colors import ListedColormap\n# Used to help create the dataset and perform mini-batch\nfrom torch.utils.data import Dataset, DataLoader"]},{"cell_type":"markdown","id":"201d919e-4710-4283-917e-afe1b56cc350","metadata":{},"outputs":[],"source":["Use the following function to plot the data: \n"]},{"cell_type":"code","id":"74690152-534f-40de-8eda-af88a71d4b13","metadata":{},"outputs":[],"source":["# Plot the data\n\ndef plot_decision_regions_2class(model,data_set):\n    cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA', '#00AAFF'])\n    cmap_bold = ListedColormap(['#FF0000', '#00FF00', '#00AAFF'])\n    X = data_set.x.numpy()\n    y = data_set.y.numpy()\n    h = .02\n    x_min, x_max = X[:, 0].min() - 0.1 , X[:, 0].max() + 0.1 \n    y_min, y_max = X[:, 1].min() - 0.1 , X[:, 1].max() + 0.1 \n    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),np.arange(y_min, y_max, h))\n    XX = torch.Tensor(np.c_[xx.ravel(), yy.ravel()])\n\n    yhat = np.logical_not((model(XX)[:, 0] > 0.5).numpy()).reshape(xx.shape)\n    plt.pcolormesh(xx, yy, yhat, cmap=cmap_light, shading='auto')\n    plt.plot(X[y[:, 0] == 0, 0], X[y[:, 0] == 0, 1], 'o', label='y=0')\n    plt.plot(X[y[:, 0] == 1, 0], X[y[:, 0] == 1, 1], 'ro', label='y=1')\n    plt.title(\"decision region\")\n    plt.legend()"]},{"cell_type":"markdown","id":"c45e47a8-524b-421a-a78d-0458954d9e02","metadata":{},"outputs":[],"source":["Use the following function to calculate accuracy: \n"]},{"cell_type":"code","id":"a8766296-66fa-4440-9819-cfc706c8d558","metadata":{},"outputs":[],"source":["# Calculate the accuracy\n\ndef accuracy(model, data_set):\n    # Rounds prediction to nearest integer 0 or 1\n    # Checks if prediction matches the actual values and returns accuracy rate\n    return np.mean(data_set.y.view(-1).numpy() == (model(data_set.x)[:, 0] > 0.5).numpy())"]},{"cell_type":"markdown","id":"b590ef4e-cf06-4303-89bc-66d0b0af36fe","metadata":{},"outputs":[],"source":["<!--Empty Space for separating topics-->\n"]},{"cell_type":"markdown","id":"9aa355d8-1a86-468c-b865-acbd74259a77","metadata":{},"outputs":[],"source":["<h2 id=\"Model\">Neural Network Module and Training Function</h2> \n"]},{"cell_type":"markdown","id":"5584e13c-1b01-4944-b4b4-8ec94a5e6b44","metadata":{},"outputs":[],"source":["Define the neural network module or class: \n"]},{"cell_type":"code","id":"dcffdd27-f2bb-44fa-9fb4-94954d922945","metadata":{},"outputs":[],"source":["# Define the class Net with one hidden layer \n\nclass Net(nn.Module):\n    \n    # Constructor\n    def __init__(self, D_in, H, D_out):\n        super(Net, self).__init__()\n        # D_in is the input size of the first layer (size of input layer)\n        # H is the outpout size of the first layer and the input size of the second layer (size of hidden layer)\n        # D_out is the output size of the second layer (size of output layer)\n        self.linear1 = nn.Linear(D_in, H)\n        self.linear2 = nn.Linear(H, D_out)\n\n    # Prediction    \n    def forward(self, x):\n        # Puts x through first layer then sigmoid function\n        x = torch.sigmoid(self.linear1(x)) \n        # Puts result of previous line through second layer then sigmoid function\n        x = torch.sigmoid(self.linear2(x))\n        # Output is a number between 0 and 1 due to the sigmoid function. Whichever the output is closer to, 0 or 1, is the class prediction\n        return x"]},{"cell_type":"markdown","id":"26522dc2-b444-4f80-a243-23e129380a2f","metadata":{},"outputs":[],"source":["Define a function to train the model: \n"]},{"cell_type":"code","id":"a1aeb613-ee8b-435e-a231-ad9a5275d8d0","metadata":{},"outputs":[],"source":["# Function to Train the Model\n\ndef train(data_set, model, criterion, train_loader, optimizer, epochs=5):\n    # Lists to keep track of cost and accuracy\n    COST = []\n    ACC = []\n    # Number of times we train on the entire dataset\n    for epoch in range(epochs):\n        # Total loss over epoch\n        total=0\n        # For batch in train laoder\n        for x, y in train_loader:\n            # Resets the calculated gradient value, this must be done each time as it accumulates if we do not reset\n            optimizer.zero_grad()\n            # Makes a prediction based on X value\n            yhat = model(x)\n            # Measures the loss between prediction and acutal Y value\n            loss = criterion(yhat, y)\n            # Calculates the gradient value with respect to each weight and bias\n            loss.backward()\n            # Updates the weight and bias according to calculated gradient value\n            optimizer.step()\n            # Cumulates loss \n            total+=loss.item()\n        # Saves cost and accuracy\n        ACC.append(accuracy(model, data_set))\n        COST.append(total)\n        \n    # Prints Cost vs Epoch graph\n    fig, ax1 = plt.subplots()\n    color = 'tab:red'\n    ax1.plot(COST, color=color)\n    ax1.set_xlabel('epoch', color=color)\n    ax1.set_ylabel('total loss', color=color)\n    ax1.tick_params(axis='y', color=color)\n    \n    # Prints Accuracy vs Epoch graph\n    ax2 = ax1.twinx()  \n    color = 'tab:blue'\n    ax2.set_ylabel('accuracy', color=color)  # we already handled the x-label with ax1\n    ax2.plot(ACC, color=color)\n    ax2.tick_params(axis='y', color=color)\n    fig.tight_layout()  # otherwise the right y-label is slightly clipped\n    \n    plt.show()\n\n    return COST"]},{"cell_type":"markdown","id":"0e6213d6-0f17-4eed-a1c6-291c83ad231e","metadata":{},"outputs":[],"source":["<!--Empty Space for separating topics-->\n"]},{"cell_type":"markdown","id":"52c67a2d-46ee-41bc-9975-3bbd22098b43","metadata":{},"outputs":[],"source":["<h2 id=\"Makeup_Data\">Make Some Data</h2> \n"]},{"cell_type":"markdown","id":"6f72d5b1-fb87-4b28-9c77-b7f5979f34b6","metadata":{},"outputs":[],"source":["Dataset class:\n"]},{"cell_type":"code","id":"f3aa286b-8035-4862-b8c9-5f0a503741f4","metadata":{},"outputs":[],"source":["# Define the class XOR_Data\n\nclass XOR_Data(Dataset):\n    \n    # Constructor\n    # N_s is the size of the dataset\n    def __init__(self, N_s=100):\n        # Create a N_s by 2 array for the X values representing the coordinates\n        self.x = torch.zeros((N_s, 2))\n        # Create a N_s by 1 array for the class the X value belongs to\n        self.y = torch.zeros((N_s, 1))\n        # Split the dataset into 4 sections\n        for i in range(N_s // 4):\n            # Create data centered around (0,0) of class 0\n            self.x[i, :] = torch.Tensor([0.0, 0.0]) \n            self.y[i, 0] = torch.Tensor([0.0])\n\n            # Create data centered around (0,1) of class 1\n            self.x[i + N_s // 4, :] = torch.Tensor([0.0, 1.0])\n            self.y[i + N_s // 4, 0] = torch.Tensor([1.0])\n    \n            # Create data centered around (1,0) of class 1\n            self.x[i + N_s // 2, :] = torch.Tensor([1.0, 0.0])\n            self.y[i + N_s // 2, 0] = torch.Tensor([1.0])\n    \n            # Create data centered around (1,1) of class 0\n            self.x[i + 3 * N_s // 4, :] = torch.Tensor([1.0, 1.0])\n            self.y[i + 3 * N_s // 4, 0] = torch.Tensor([0.0])\n\n            # Add some noise to the X values to make them different\n            self.x = self.x + 0.01 * torch.randn((N_s, 2))\n        self.len = N_s\n\n    # Getter\n    def __getitem__(self, index):    \n        return self.x[index],self.y[index]\n    \n    # Get Length\n    def __len__(self):\n        return self.len\n    \n    # Plot the data\n    def plot_stuff(self):\n        plt.plot(self.x[self.y[:, 0] == 0, 0].numpy(), self.x[self.y[:, 0] == 0, 1].numpy(), 'o', label=\"y=0\")\n        plt.plot(self.x[self.y[:, 0] == 1, 0].numpy(), self.x[self.y[:, 0] == 1, 1].numpy(), 'ro', label=\"y=1\")\n        plt.legend()"]},{"cell_type":"markdown","id":"fed7965d-0c8e-4071-ae1b-cb9c35ecc7fe","metadata":{},"outputs":[],"source":["Dataset object:\n"]},{"cell_type":"code","id":"d978e175-086c-45e9-b65a-f584f63691ce","metadata":{},"outputs":[],"source":["# Create dataset object\n\ndata_set = XOR_Data()\ndata_set.plot_stuff()"]},{"cell_type":"markdown","id":"830761b2-8e87-4def-97bc-05f0454cb2a4","metadata":{},"outputs":[],"source":["<!--Empty Space for separating topics-->\n"]},{"cell_type":"markdown","id":"8af68ed1-7a2a-4699-b5b5-9586328b4823","metadata":{},"outputs":[],"source":["<h2 id=\"One\">One Neuron</h2> \n"]},{"cell_type":"markdown","id":"e7bcfc81-e75f-4250-a502-a16472291524","metadata":{},"outputs":[],"source":["<h3>Try</h3>\n"]},{"cell_type":"markdown","id":"e4ffb0a9-dff1-4e7f-aae5-38e53f8a7d6c","metadata":{},"outputs":[],"source":["Create a neural network <code>model</code> with one neuron in the hidden layer. Then, use the following code to train it:\n"]},{"cell_type":"code","id":"a24a5be2-7440-4ebf-b79c-b282e726334f","metadata":{},"outputs":[],"source":["# Practice: create a model with one neuron\n# Type your code here\nmodel = Net(2, 1, 1)"]},{"cell_type":"markdown","id":"138b3321-016e-4608-ab0a-4bcb7255ce86","metadata":{},"outputs":[],"source":["Double-click <b>here</b> for the solution.\n","\n","<!-- \n","model = Net(2, 1, 1)\n","-->\n"]},{"cell_type":"code","id":"2d7a4d76-7bd0-43e8-86cb-87a9d7e1954e","metadata":{},"outputs":[],"source":["# Train the model\n\nlearning_rate = 0.1\n# We create a criterion which will measure loss\ncriterion = nn.BCELoss()\n# Create an optimizer that updates model parameters using the learning rate and gradient\noptimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n# Create a Data Loader for the training data with a batch size of 1 \ntrain_loader = DataLoader(dataset=data_set, batch_size=1)\n# Using the training function train the model on 500 epochs\nLOSS12 = train(data_set, model, criterion, train_loader, optimizer, epochs=500)\n# Plot the data with decision boundaries\nplot_decision_regions_2class(model, data_set)"]},{"cell_type":"markdown","id":"454ae700-42cb-463d-9294-a5c2a5e803dd","metadata":{},"outputs":[],"source":["<!--Empty Space for separating topics-->\n"]},{"cell_type":"markdown","id":"8821c2f4-a38c-4002-aaeb-18d9b0b0f49e","metadata":{},"outputs":[],"source":["<h2 id=\"Two\">Two Neurons</h2> \n"]},{"cell_type":"markdown","id":"7d708456-f0e3-4fd6-90c4-0ef78befd959","metadata":{},"outputs":[],"source":["<h3>Try</h3>\n"]},{"cell_type":"markdown","id":"e09123b4-7a7f-4b68-8099-60687c0e7495","metadata":{},"outputs":[],"source":["Create a neural network <code>model</code> with two neurons in the hidden layer. Then, use the following code to train it:\n"]},{"cell_type":"code","id":"18e4ae6d-c702-4512-9e27-90d534c73bf6","metadata":{},"outputs":[],"source":["# Practice: create a model with two neuron\n# Type your code here\nmodel = Net(2, 2, 1)"]},{"cell_type":"markdown","id":"388aeff4-a3f9-4b65-8b89-4660f750ec47","metadata":{},"outputs":[],"source":["Double-click <b>here</b> for the solution.\n","\n","<!-- \n","model = Net(2, 2, 1)\n","-->\n"]},{"cell_type":"code","id":"c5c4829b-fcde-4568-bab3-aedd0cb5bd83","metadata":{},"outputs":[],"source":["# Train the model\n\nlearning_rate = 0.1\n# We create a criterion which will measure loss\ncriterion = nn.BCELoss()\n# Create an optimizer with the model parameters and learning rate\noptimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n# Create a Data Loader for the training data with a batch size of 1 \ntrain_loader = DataLoader(dataset=data_set, batch_size=1)\n# Using the training function train the model on 500 epochs\nLOSS12 = train(data_set, model, criterion, train_loader, optimizer, epochs=500)\n# Plot the data with decision boundaries\nplot_decision_regions_2class(model, data_set)"]},{"cell_type":"markdown","id":"369b2e3a-4135-425b-b3b2-98618de5f736","metadata":{},"outputs":[],"source":["<!--Empty Space for separating topics-->\n"]},{"cell_type":"markdown","id":"0708370d-f378-476e-a47d-df67597b528f","metadata":{},"outputs":[],"source":["<h2 id=\"Three\">Three Neurons</h2> \n"]},{"cell_type":"markdown","id":"de72fb73-e111-4e24-a1f4-cb2d9bed4d74","metadata":{},"outputs":[],"source":["<h3>Try</h3>\n"]},{"cell_type":"markdown","id":"acdf12d4-e2a8-4b03-a222-404e59897889","metadata":{},"outputs":[],"source":["Create a neural network <code>model</code> with three neurons in the hidden layer. Then, use the following code to train it:\n"]},{"cell_type":"code","id":"a49cc3dc-872f-47c1-8287-7cef28ec0d9f","metadata":{},"outputs":[],"source":["# Practice: create a model with two neuron\n# Type your code here\nmodel = Net(2, 3, 1)"]},{"cell_type":"markdown","id":"54efd1b5-97b3-4dee-8d76-6a14ac53bf9e","metadata":{},"outputs":[],"source":["Double-click <b>here</b> for the solution.\n","\n","<!-- \n","model = Net(2, 3, 1)\n","-->\n"]},{"cell_type":"code","id":"1c460511-7475-4bf2-8a61-bd4418b2b8f4","metadata":{},"outputs":[],"source":["# Train the model\n\nlearning_rate = 0.1\n# We create a criterion which will measure loss\ncriterion = nn.BCELoss()\n# Create an optimizer with the model parameters and learning rate\noptimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n# Create a Data Loader for the training data with a batch size of 1 \ntrain_loader = DataLoader(dataset=data_set, batch_size=1)\n# Using the training function train the model on 500 epochs\nLOSS12 = train(data_set, model, criterion, train_loader, optimizer, epochs=500)\n# Plot the data with decision boundaries\nplot_decision_regions_2class(model, data_set)"]},{"cell_type":"markdown","id":"8cc8798e-b335-4f53-b30a-d1be141ffa2d","metadata":{},"outputs":[],"source":["<!--Empty Space for separating topics-->\n"]},{"cell_type":"markdown","id":"fb6443e6-656b-49cf-9f87-96634b9ecd2c","metadata":{},"outputs":[],"source":["<h2>About the Authors:</h2> \n","\n","<a href=\"https://www.linkedin.com/in/joseph-s-50398b136/\">Joseph Santarcangelo</a> has a PhD in Electrical Engineering, his research focused on using machine learning, signal processing, and computer vision to determine how videos impact human cognition. Joseph has been working for IBM since he completed his PhD. \n"]},{"cell_type":"markdown","id":"1cac3546-588e-43bc-95e5-c82823b19bef","metadata":{},"outputs":[],"source":["Other contributors: <a href=\"https://www.linkedin.com/in/michelleccarey/\">Michelle Carey</a>, <a href=\"https://www.linkedin.com/in/jiahui-mavis-zhou-a4537814a\">Mavis Zhou</a>\n"]},{"cell_type":"markdown","id":"b4522961-f835-4af3-b764-1e425cbbe1c0","metadata":{},"outputs":[],"source":["\n","<!--## Change Log\n","\n","|  Date (YYYY-MM-DD) |  Version | Changed By  |  Change Description |\n","|---|---|---|---|\n","| 2025-07-11  | 2.0  | Sathya  |  Converted to Jupyterlab current |\n","| 2020-09-23  | 2.0  | Shubham  |  Migrated Lab to Markdown and added to course repo in GitLab |-->\n","\n"]},{"cell_type":"markdown","id":"5a87b9f7-cc1d-4765-b280-d2da72c70139","metadata":{},"outputs":[],"source":["<hr>\n"]},{"cell_type":"markdown","id":"dc9e083b-ed39-4083-a955-ad6a15221f6c","metadata":{},"outputs":[],"source":["\n","## <h3 align=\"center\"> Â© IBM Corporation. All rights reserved. <h3/>\n"]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3 (ipykernel)","language":"python"},"language_info":{"name":"python","version":"3.12.8","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"prev_pub_hash":"da4dea73c0ddcb119ec7162e56d1a932e84e8e5e5a421c4b829995614597cadc"},"nbformat":4,"nbformat_minor":4}