{"cells":[{"cell_type":"markdown","id":"924a311d-bc6f-4fe3-bde8-64bdd12fe7f8","metadata":{},"outputs":[],"source":["<p style=\"text-align:center\">\n","    <a href=\"https://skills.network\" target=\"_blank\">\n","    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n","    </a>\n","</p>\n"]},{"cell_type":"markdown","id":"277d7ff2-8ae9-4846-84da-f31516597b00","metadata":{},"outputs":[],"source":["<h1>Lab: Car Detection with Haar Classifiers</h1>\n"]},{"cell_type":"markdown","id":"6615717d-8a5f-49b3-98ab-a83db9baa9ad","metadata":{},"outputs":[],"source":["## Overview\n"]},{"cell_type":"markdown","id":"d3929267-f2c7-4756-b965-d8d35da3411d","metadata":{},"outputs":[],"source":["In this lab, you will apply a pre-trained Haar cascade classifier to your uploaded car image to perform vehicle detection.\n"]},{"cell_type":"markdown","id":"2a725ec7-f4f8-4509-af08-a870a4b2ccf7","metadata":{},"outputs":[],"source":["# Objectives\n"]},{"cell_type":"markdown","id":"b7646fb7-0650-4127-85d7-6de50cc4aec3","metadata":{},"outputs":[],"source":["Haar Cascade is a machine learning method based on Haar wavelet to identify objects in an image or a video. We will use the [OpenCV](http://opencv.org/) library. It is based on the concept of features proposed by Paul Viola and Michael Jones in their paper \"Rapid Object Detection using a Boosted Cascade of Simple Features\".\n"]},{"cell_type":"markdown","id":"348d9bc0-e900-4436-a5bf-3c59f4be2971","metadata":{},"outputs":[],"source":["## Table of Contents\n"]},{"cell_type":"markdown","id":"23d70090-9175-4bcc-a30a-874aa8139a79","metadata":{},"outputs":[],"source":["This notebook is organized into the following sections:\n","        <ul>\n","            <li>[Install and Import Libraries](#Install-and-Import-Libraries) </li>\n","            <li>[Image Processing](#Image-Processing)</li>\n","            <li>[Practice Exercise - Upload your image](#Practice-Exercise---Upload-your-image) </li>\n","            </li>      \n","        </ul>\n","    </li>\n","</ul>\n"]},{"cell_type":"markdown","id":"64148e87-e3d7-4d4e-b59a-8945b35801e0","metadata":{},"outputs":[],"source":["## Install and Import Libraries\n"]},{"cell_type":"code","id":"aafff22a-06ed-4823-a830-e8a9bd7fd8d4","metadata":{},"outputs":[],"source":["!pip install opencv-python-headless\n!pip install numpy pandas matplotlib  --quiet\n"]},{"cell_type":"markdown","id":"e5d81043-65e9-4222-8c4f-122a5d41426a","metadata":{},"outputs":[],"source":["**Import important libraries and Define auxilary functions**\n"]},{"cell_type":"code","id":"70ddcad7-6877-4159-916e-3b513ae30cb0","metadata":{},"outputs":[],"source":["import urllib.request\nimport cv2\nfrom matplotlib import pyplot as plt\n%matplotlib inline"]},{"cell_type":"markdown","id":"36dca597-dd81-45bf-bd27-d4d3ab7d2b1c","metadata":{},"outputs":[],"source":["**Create a function that cleans up and displays the image:**\n","\n","The `plt_show()` function is a utility used to visualize images in Jupyter notebooks or scripts using matplotlib. \n","\n","It supports both color and grayscale display formats. By default, OpenCV loads images in BGR color format, which needs to be converted to RGB for correct display with matplotlib. This function handles that conversion when gray=False. \n","\n","It also allows adding a title and customizing the display size. The gray=True flag enables viewing the image in grayscale, which is helpful when working with edge detection, object detection, or when inspecting single-channel data like masks or features. This utility is especially useful during data preprocessing, model evaluation, and debugging steps in computer vision tasks.\n"]},{"cell_type":"code","id":"4fa9a0ea-da0c-4dde-a5e2-e585d0550de7","metadata":{},"outputs":[],"source":["# Function to display images using matplotlib\ndef plt_show(image, title=\"\", gray=False, size=(10, 10)):\n    temp = image.copy()  # Make a copy to avoid altering the original image\n\n    if not gray:\n        # Convert image from BGR (OpenCV default) to RGB (matplotlib expects RGB)\n        temp = cv2.cvtColor(temp, cv2.COLOR_BGR2RGB)\n\n    plt.figure(figsize=size)  # Set figure size\n    plt.imshow(temp, cmap='gray' if gray else None)  # Display image; grayscale if 'gray=True'\n    plt.title(title)  # Set the title above the image\n    plt.axis(\"off\")  # Hide axis ticks and labels for a cleaner look\n    plt.show()  # Render the image\n"]},{"cell_type":"markdown","id":"90a8a587-9f3b-44b9-88e0-edd1ca4b0300","metadata":{},"outputs":[],"source":["**Create a function to detect cars in an image**\n","\n","This function detects cars in an input image using a pre-trained Haar cascade classifier. It first converts the image to grayscale, as Haar classifiers are designed to work on single-channel images.\n","\n","It then applies detectMultiScale() to find car-like regions. To improve reliability, it filters the detections by choosing only the largest bounding box, assuming that the main subject (the car) dominates the image. \n","\n","After detecting, it draws a green rectangle around the car and displays the result using a helper function (plt_show). You can tweak the scaleFactor, minNeighbors, and size parameters to improve detection accuracy based on your input image resolution.\n"]},{"cell_type":"code","id":"57478b9f-b965-43a3-9c40-e956966f24bc","metadata":{},"outputs":[],"source":["def detect_obj(image):\n    # Make a copy of the original image to avoid drawing on the original\n    img_copy = image.copy()\n    \n    # Convert the image to grayscale because Haar cascades work on single-channel images\n    gray = cv2.cvtColor(img_copy, cv2.COLOR_BGR2GRAY)\n\n    # Detect objects using Haar cascade with relaxed parameters\n    cars = detector.detectMultiScale(\n        gray,\n        scaleFactor=1.05,  # Slightly finer scale steps for detecting objects at different sizes\n        minNeighbors=2,    # Lower value increases sensitivity (may result in more false positives)\n        minSize=(30, 30),  # Ignore very small detections\n        maxSize=(700, 700) # Ignore very large detections\n    )\n\n    # If detections are found, keep only the largest one (assuming it's the main car)\n    if len(cars) > 0:\n        # Sort detections by area (width * height), descending\n        cars = sorted(cars, key=lambda box: box[2] * box[3], reverse=True)\n        # Keep only the largest bounding box to avoid multiple overlapping detections\n        cars = [cars[0]]\n\n    # Print the number of cars detected (after filtering)\n    print(f\"Detected: {len(cars)} car(s)\")\n\n    # Draw a green rectangle around the detected car(s)\n    for (x, y, w, h) in cars:\n        cv2.rectangle(img_copy, (x, y), (x + w, y + h), (0, 255, 0), 2)\n\n    # Display the image with the detected car(s)\n    plt_show(img_copy, title=\"Detected Car\")\n"]},{"cell_type":"markdown","id":"76f2e7b2-1593-4e9a-82fe-a26ec4f0785e","metadata":{},"outputs":[],"source":["## Image Processing\n","\n","You are preparing the environment for car detection by:\n","\n","    Downloading the pre-trained Haar cascade XML for car detection.\n","    \n","    Creating a detector using OpenCV's CascadeClassifier.\n","    \n","    Loading a test image from a remote URL.\n","    \n","    Displaying the image using a custom plt_show() function.\n","    \n","    Detecting the object using detect_obj() function.\n"]},{"cell_type":"markdown","id":"8d056b4e-100d-4273-ac0e-d7251b499a38","metadata":{},"outputs":[],"source":["**Download Haar Cascade XML file from a remote URL**\n"]},{"cell_type":"markdown","id":"6d4cec83-c1a4-4cfc-86a2-2cceb3ef0b21","metadata":{},"outputs":[],"source":["Load pre-trained classifier from [andrewssobral](https://raw.githubusercontent.com/andrewssobral/vehicle_detection_haarcascades/master/cars.xml) git repository, training takes a long time but prediction is fast.\n"]},{"cell_type":"code","id":"965c6ec4-a094-421e-aca5-c9bf274b3041","metadata":{},"outputs":[],"source":["# Define the URL of the Haar Cascade file for car detection.\n# This file contains a pre-trained classifier (feature patterns) for detecting cars.\nhaarcascade_url = 'https://raw.githubusercontent.com/andrewssobral/vehicle_detection_haarcascades/master/cars.xml'\n\n# Define the local filename to save the downloaded XML file.\nhaar_name = \"cars.xml\"\n\n# Download the XML file from the URL and save it locally as 'cars.xml'.\n# urllib.request.urlretrieve() fetches the file from the internet.\nurllib.request.urlretrieve(haarcascade_url, haar_name)\n"]},{"cell_type":"markdown","id":"168a8ce8-c32b-43c6-8e26-b7a4bb7eb5c8","metadata":{},"outputs":[],"source":["**Get the detector using the `cv2.CascadeClassifier()` module on the pretrained dataset**\n"]},{"cell_type":"code","id":"b223bc2c-c967-40aa-ab45-6ef3a7dfc6b8","metadata":{},"outputs":[],"source":["detector = cv2.CascadeClassifier(haar_name)"]},{"cell_type":"markdown","id":"2ed61a9e-2ee7-408b-86ae-da966d2c3495","metadata":{},"outputs":[],"source":["**Read a sample image**\n"]},{"cell_type":"code","id":"c1cb3bf1-90ae-4a1f-9418-95ab119b1ac3","metadata":{},"outputs":[],"source":["# Define the URL of the sample image (a car on the road).\nimage_url = \"https://s3.us.cloud-object-storage.appdomain.cloud/cf-courses-data/CognitiveClass/CV0101/Dataset/car-road-behind.jpg\"\n\n# Specify the name to save the downloaded image locally.\nimage_name = \"car-road-behind.jpg\"\n\n# Download the image from the given URL and save it with the specified name.\nurllib.request.urlretrieve(image_url, image_name)\n\n# Load the downloaded image using OpenCV (reads image in BGR format by default).\nimage = cv2.imread(image_name)\n"]},{"cell_type":"markdown","id":"28739c2c-5b60-4c93-b5d8-6124b9efb59f","metadata":{},"outputs":[],"source":["**Plot the image**\n"]},{"cell_type":"code","id":"7683df4e-60ca-48e8-a60f-59683c56f5bb","metadata":{},"outputs":[],"source":["plt_show(image)"]},{"cell_type":"markdown","id":"7b854280-9180-47b2-9ed7-a2a451dd077c","metadata":{},"outputs":[],"source":["**Detect the object on loaded image**\n"]},{"cell_type":"code","id":"22f4eb0a-dc7c-4c85-9999-e5fc13aff21b","metadata":{},"outputs":[],"source":["detect_obj(image)"]},{"cell_type":"markdown","id":"2f7c4d87-78aa-483e-8ceb-2eb800b589b8","metadata":{},"outputs":[],"source":["# Practice Exercise - Upload your image\n"]},{"cell_type":"markdown","id":"c303980f-a024-49a3-a525-6c7f801a3cda","metadata":{},"outputs":[],"source":["Upload your image and see if your car will be correctly detected.\n","<p><b>Instructions on how to upload an image:</b></p>\n","Use the upload button and upload the image from your local machine\n","<center>\n","    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-CV0101EN-SkillsNetwork/images/instruction.png\" width=\"300\"  />\n","</center>\n"]},{"cell_type":"markdown","id":"a4c0e810-2b86-4c26-8370-44d47e511033","metadata":{},"outputs":[],"source":["The image will now be in the directory in which you are working in. To read the image in a new cell, use the <code>cv2.imread</code>  function. For example, I uploaded <code>anothercar.jpg</code>  into my current working directory - <code>cv2.imread(\"anothercar.jpg\")</code>.\n","\n","\n","<center>\n","    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-CV0101EN-SkillsNetwork/images/instruction2.png\" width=\"300\"  />\n","</center>\n"]},{"cell_type":"markdown","id":"a9ada6dc-211d-426f-9787-ad5308729b8c","metadata":{},"outputs":[],"source":["Else use the below images to test.\n"]},{"cell_type":"code","id":"79e728f1-a822-48cc-b64a-31ee490d5baf","metadata":{},"outputs":[],"source":["!wget \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/h3EzuZiidvgdOxPA_yVVWg/car1.jpg\"\n!wget \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/eKnqJ2xWDdanVdLH6WgOmQ/car2.jpg\"\n!wget \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/JDjRn_0f5kx9DRT2xv_mew/nocar.jpg\""]},{"cell_type":"markdown","id":"1d975298-28c0-4451-99d8-9bbe819b3fc7","metadata":{},"outputs":[],"source":["Replace your_uploaded_file below with the name of your image as seen in your directory. In case you are using the downloaded images given in the notebook then use as `car1.jpg` or `car2.jpg` or `nocar.jpg`\n"]},{"cell_type":"code","id":"f4bd82af-0220-4c5e-b282-12cd6b942afb","metadata":{},"outputs":[],"source":["## replace \"your_uploaded_file\" with your file name\nmy_image = cv2.imread(\"car1.jpg\")"]},{"cell_type":"code","id":"22cdcade-e80b-445f-8242-974c100e5c54","metadata":{},"outputs":[],"source":["if my_image is None:\n    print(\"Error: image is empty or not loaded properly.\")  \n"]},{"cell_type":"markdown","id":"30ede139-92a1-4204-a772-4db2fdabb7fd","metadata":{},"outputs":[],"source":["Run the Cascade classifier on your model to detect the object.\n"]},{"cell_type":"code","id":"4207ccd4-56f1-4829-a4d4-00f76ece255a","metadata":{},"outputs":[],"source":["detect_obj(my_image)"]},{"cell_type":"markdown","id":"3b825431-3fc6-45fb-acf9-11d99dd7ae71","metadata":{},"outputs":[],"source":["### Congratulations! You've completed the Car Detection lab using Haar Cascade Classifiers.\n","You successfully applied a pre-trained model to detect vehicle in images using OpenCV.\n"]},{"cell_type":"markdown","id":"674ad7cd-7aef-4658-af23-0e1479d38f88","metadata":{},"outputs":[],"source":["<h2>Authors</h2>\n"]},{"cell_type":"markdown","id":"874e9e52-38c8-46bf-be3c-6825b166cdd5","metadata":{},"outputs":[],"source":["<a href=\"https://www.linkedin.com/in/aije-egwaikhide/\">Aije Egwaikhide</a> \n","\n","<a href=\"https://www.linkedin.com/in/nayefaboutayoun/\" target=\"_blank\">Nayef Abou Tayoun</a>\n","\n","[Sathya Priya](https://www.linkedin.com/in/sathya-priya-06120a17a/) \n"]},{"cell_type":"markdown","id":"f766e65c-75e2-4e78-b702-7fc6374f260f","metadata":{},"outputs":[],"source":["<!--<h2>Change Log</h2>-->\n"]},{"cell_type":"markdown","id":"370bd65b-c1c1-4e20-81ba-8da43874c1f8","metadata":{},"outputs":[],"source":["<!--<table>\n","    <tr>\n","        <th>Date (YYYY-MM-DD)</th>\n","        <th>Version</th>\n","        <th>Changed By</th>\n","        <th>Change Description</th>\n","    </tr>\n","    <tr>\n","        <td>2025-06-28</td>\n","        <td>1.1</td>\n","        <td>Sathya Priya</td>\n","        <td>Created and Converted the lab to JupyterCurrent notebook </td>\n","    </tr>\n","    <tr>\n","        <td>2021-04-09</td>\n","        <td>1.0</td>\n","        <td>Aije</td>\n","        <td>Updated to new template</td>\n","    </tr>\n","    <tr>\n","        <td>2021-03-02</td>\n","        <td>0.2</td>\n","        <td>Aije</td>\n","        <td>Updated code and instructions and added practice exercise</td>\n","    </tr>\n","    <tr>\n","        <td>2020-08-18</td>\n","        <td>0.1</td>\n","        <td>Nayef</td>\n","        <td>Created original version of the lab</td>\n","    </tr>\n","</table>\n","-->\n"]},{"cell_type":"markdown","id":"040fd22a-0930-451d-a956-f9ed1224b3e4","metadata":{},"outputs":[],"source":["<h3 align=\"center\"> &#169; IBM Corporation. All rights reserved. <h3/>\n"]},{"cell_type":"code","id":"4a14dca1-9a00-4ec0-b3d3-aa1781e0d770","metadata":{},"outputs":[],"source":[""]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.8"},"prev_pub_hash":"e4c04410d74e0df52cd8a6d783c0c8ed7f1cb55c5f2ca11fb8054376679f1a5b"},"nbformat":4,"nbformat_minor":4}